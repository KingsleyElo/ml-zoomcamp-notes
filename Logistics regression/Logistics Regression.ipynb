{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1f5cec1-c6d9-4a92-be39-97e850034918",
   "metadata": {},
   "source": [
    "## **Logistics Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491ac0c-7e81-4c56-b387-1cb88fd1ae2e",
   "metadata": {},
   "source": [
    "### 1. Short History of Logistic Regression\n",
    "\n",
    "The logistic function was introduced in the **19th century** by **Pierre-FranÃ§ois Verhulst** to model population growth.\n",
    "\n",
    "In the **early 20th century**, statisticians realized that the same function could model **binary outcomes** (yes/no, success/failure).\n",
    "\n",
    "By the **1940sâ€“1950s**, logistic regression was formally developed as a statistical method, especially in **biostatistics and social sciences**, to model probabilities of events that have only two possible outcomes.\n",
    "\n",
    "**Today**, logistic regression is one of the foundational algorithms in machine learning, widely used for problems such as:\n",
    "\n",
    "- **Churn prediction**\n",
    "- **Fraud detection**\n",
    "- **Medical diagnosis**\n",
    "\n",
    "**Because it is**:\n",
    "- **Interpretable**\n",
    "- **Probabilistic** \n",
    "- **Mathematically well-grounded**\n",
    "\n",
    "---\n",
    "\n",
    "### 2. What is Logistic Regression?\n",
    "\n",
    "**Logistic regression** is a **supervised learning algorithm** used for **binary classification**.\n",
    "\n",
    "**Its goal**: Model the probability that an outcome belongs to the **positive class** (e.g., customer churns).\n",
    "\n",
    "**Key difference**: Instead of predicting a class label directly, logistic regression predicts a **probability**, which is then converted into a class decision using a **threshold** (commonly **0.5**).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Why the Linear Model Output is Not a Probability\n",
    "\n",
    "Logistic regression starts with a **linear model**, just like linear regression:\n",
    "\n",
    "$z = 0.8x - 1.2$\n",
    "\n",
    "\n",
    "**Key issue**:\n",
    "\n",
    "**Linear model outputs**: `z âˆˆ (-âˆž, +âˆž)` (any real number)\n",
    "\n",
    "**Probabilities must satisfy**: `0 â‰¤ p â‰¤ 1`\n",
    "\n",
    "**Therefore**:\n",
    "- Linear output `z` **cannot** be interpreted as a probability\n",
    "- We need a transformation that maps all real numbers into the interval `(0,1)`\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Log-Odds (Logit): Linking Linear Models to Probability\n",
    "\n",
    "Instead of modeling probability directly, logistic regression models the **log-odds**, also called the **logit**.\n",
    "\n",
    "**Odds**:\n",
    "\n",
    "$$odds = \\frac{p}{1 - p}$$\n",
    "\n",
    "\n",
    "**Log-odds (logit)**:\n",
    "\n",
    "$$\\log\\left(\\frac{p}{1 - p}\\right)$$\n",
    "\n",
    "\n",
    "**Important property**:\n",
    "\n",
    "- Log-odds range: (-âˆž, +âˆž)\n",
    "- Linear model range: (-âˆž, +âˆž)\n",
    "  \n",
    "âœ“ Perfect match!\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Logistic Regression Model (Example)\n",
    "\n",
    "**\"Logistics Regression Fits a linear model to the log-odds\"**:\n",
    "\n",
    "$$\\log\\left(\\frac{p}{1-p}\\right) = 0.8x - 1.2$$\n",
    "\n",
    "\n",
    "\n",
    "**Left-hand side**: Log-odds (logit) of churning  \n",
    "**Right-hand side**: Linear regression on feature `x`\n",
    "\n",
    "**This equation means**:\n",
    "- Features influence the **log-odds of churn linearly**\n",
    "- **Not** the probability directly\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Converting Log-Odds into a Valid Probability\n",
    "\n",
    "To recover the probability `p`, we solve the log-odds equation.\n",
    "\n",
    "This leads to the **logistic (sigmoid) function**:\n",
    "\n",
    "$$p = \\frac{1}{1 + e^{-(0.8x - 1.2)}}$$\n",
    "\n",
    "\n",
    "**Properties of the logistic function**:\n",
    "- Maps **any real number** to `(0,1)`\n",
    "- Produces a **smooth, interpretable probability**\n",
    "- **Ensures outputs are always valid probabilities**\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Final Interpretation\n",
    "\n",
    "1. Linear model â†’ z = 0.8x - 1.2 (log-odds score)\n",
    "\n",
    "2. Logistic function â†’ p = sigmoid(z) (probability)\n",
    "\n",
    "3. Threshold â†’ Class decision (p > 0.5 = churn)\n",
    "\n",
    "\n",
    "**Complete flow**:\n",
    "\n",
    "Features â†’ Linear Model â†’ Log-odds â†’ Sigmoid â†’ Probability â†’ Class\n",
    "\n",
    "\n",
    "**That's logistic regression!** ðŸŽ¯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86caf3d7-1bd5-4036-8036-242b6ca5a9f2",
   "metadata": {},
   "source": [
    "### **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b4aa2f-888e-4df3-a85b-ad1f9155c25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
